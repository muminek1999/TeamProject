import pandas as pd
from joblib import load
from functions import extract_features


def test_model_live(csv_path, n):
    try:
        model = load("model.joblib")
    except FileNotFoundError:
        print("‚ùå  File model.joblib not found. First run: python main.py train <csv_path>")
        return

    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"‚ùå  Error loading CSV file: {e}")
        return

    if n > len(df):
        print(f"‚ö†Ô∏è  Requested number of samples ({n}) exceeds dataset size ({len(df)}). Using all available data")
        n = len(df)

    n_bad = int(n * 0.2)
    n_good = n - n_bad

    df_bad = df[df['label'] == 'bad'].sample(n=n_bad, replace=True)
    df_good = df[df['label'] == 'good'].sample(n=n_good, replace=False)

    df_sample = pd.concat([df_bad, df_good]).sample(frac=1)

    print(df_bad)

    feat_df = df_sample.apply(extract_features, axis=1, result_type='expand')
    feat_df = pd.get_dummies(feat_df, columns=['tld', 'geo_loc'], prefix=['tld', 'geo'])

    y_true = df_sample['label'].map({'good': 1, 'bad': 0})

    model_features = model.feature_names_in_
    missing_cols = [col for col in model_features if col not in feat_df.columns]
    missing_df = pd.DataFrame(0, index=feat_df.index, columns=missing_cols)
    feat_df = pd.concat([feat_df, missing_df], axis=1)
    X = feat_df[model_features]

    y_pred = model.predict(X)
    correct = (y_true == y_pred).sum()

    for idx, row in df_sample.iterrows():
        url = row['url']
        true_label = 'Benign' if row['label'] == 'good' else 'Malicious'
        pred_label = 'Benign' if model.predict(X.loc[[idx]])[0] == 1 else 'Malicious'
        print(f"üîó {url}\n   ‚ñ∂Ô∏è  Decision: {pred_label} | üéØ True Label: {true_label}\n")

    print(f"‚úÖ  Correct predictions: {correct} / {n}\n")
